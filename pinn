import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers
import matplotlib.pyplot as plt

# ---------------------- Configuración ----------------------
tf.random.set_seed(0)
np.random.seed(0)

# Función para crear una red neuronal simple
def crear_red(neuronas=20):
    model = models.Sequential([
        layers.Input(shape=(1,)),         # Entrada
        layers.Dense(neuronas, activation='tanh'),
        layers.Dense(neuronas, activation='tanh'),
        layers.Dense(1)                   # Salida escalar
    ])
    return model

# ---------------------- Ecuación (a) xy' + y = x^2 cos(x), y(0)=0 ----------------------
x_a = np.linspace(-5, 5, 200).reshape(-1,1).astype(np.float32)
y_a_true = x_a * np.sin(x_a)  # Solución analítica

model_a = crear_red()
x_tf_a = tf.convert_to_tensor(x_a)
optimizer_a = optimizers.Adam(learning_rate=0.01)

for epoch in range(3000):
    with tf.GradientTape(persistent=True) as tape:
        tape.watch(x_tf_a)
        y_pred = model_a(x_tf_a)
        y_x = tape.gradient(y_pred, x_tf_a)
        f = x_tf_a * y_x + y_pred - x_tf_a**2 * tf.cos(x_tf_a)
        loss = tf.reduce_mean(tf.square(f))
        # Condición inicial y(0)=0
        x0 = tf.constant([[0.0]], dtype=tf.float32)
        y0_pred = model_a(x0)
        loss += tf.square(y0_pred)
    grads = tape.gradient(loss, model_a.trainable_variables)
    optimizer_a.apply_gradients(zip(grads, model_a.trainable_variables))
    del tape

y_a_pred = model_a(x_a).numpy()

# ---------------------- Ecuación (b) y'' = -y, y(0)=1, y'(0)=-0.5 ----------------------
x_b = np.linspace(-5, 5, 200).reshape(-1,1).astype(np.float32)
y_b_true = np.cos(x_b) - 0.5*np.sin(x_b)  # Solución analítica

model_b = crear_red()
x_tf_b = tf.convert_to_tensor(x_b)
optimizer_b = optimizers.Adam(learning_rate=0.01)

for epoch in range(3000):
    with tf.GradientTape(persistent=True) as tape:
        tape.watch(x_tf_b)
        y_pred = model_b(x_tf_b)
        y_x = tape.gradient(y_pred, x_tf_b)
        y_xx = tape.gradient(y_x, x_tf_b)
        f = y_xx + y_pred
        loss = tf.reduce_mean(tf.square(f))
        # Condiciones iniciales
        x0 = tf.constant([[0.0]], dtype=tf.float32)
        # y(0)=1
        y0_pred = model_b(x0)
        # y'(0) = -0.5
        with tf.GradientTape() as tape2:
            tape2.watch(x0)
            y0_val = model_b(x0)
        y0p_pred = tape2.gradient(y0_val, x0)
        loss += tf.square(y0_pred - 1.0) + tf.square(y0p_pred + 0.5)
    grads = tape.gradient(loss, model_b.trainable_variables)
    optimizer_b.apply_gradients(zip(grads, model_b.trainable_variables))
    del tape

y_b_pred = model_b(x_b).numpy()

# ---------------------- Graficar resultados ----------------------
plt.figure(figsize=(12,5))

# (a)
plt.subplot(1,2,1)
plt.plot(x_a, y_a_true, label='Solución analítica', color='blue')
plt.plot(x_a, y_a_pred, '--', label='Red neuronal', color='red')
plt.title("ED: xy' + y = x^2 cos(x), y(0)=0")
plt.legend()

# (b)
plt.subplot(1,2,2)
plt.plot(x_b, y_b_true, label='Solución analítica', color='blue')
plt.plot(x_b, y_b_pred, '--', label='Red neuronal', color='red')
plt.title("ED: y'' = -y, y(0)=1, y'(0)=-0.5")
plt.legend()

plt.tight_layout()
plt.show()

